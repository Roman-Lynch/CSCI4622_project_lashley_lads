{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ingest XLS data into dataframes to train and test on\n",
    "\"\"\"\n",
    "def load_data(filepath, target_column):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "train_filepath = \"/Users/ethanmcaleavy/Documents/CompSci /CSCI 4622/Project/CSCI4622_project_lashley_lads/data_for_KNN_train.csv\"\n",
    "test_filepath = \"/Users/ethanmcaleavy/Documents/CompSci /CSCI 4622/Project/CSCI4622_project_lashley_lads/data_for_KNN_test.csv\"    \n",
    "target_column = \"log_price\" \n",
    "\n",
    "X_train, y_train = load_data(train_filepath, target_column)\n",
    "X_test, y_test = load_data(test_filepath, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLasso(object):\n",
    "    def __init__(self, alpha, normalize=False):\n",
    "        self.alpha = alpha\n",
    "        self.coefficients = None\n",
    "        self.intercept = None\n",
    "        self.normalize = normalize\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = linear_model.Lasso(alpha=alpha, fit_intercept=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_nonzero_coefs, coefs_norm = 0, 0\n",
    "        if self.normalize: \n",
    "            X = self.scaler.fit_transform(X)\n",
    "\n",
    "        self.model.fit(X, y)\n",
    "        self.intercept = self.model.intercept_\n",
    "        self.coefficients = self.model.coef_\n",
    "\n",
    "        num_nonzero_coefs = np.sum(self.coefficients != 0)\n",
    "        coefs_norm = np.linalg.norm(self.coefficients)\n",
    "            \n",
    "        return num_nonzero_coefs, coefs_norm\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        root_mean_squared_error = 0\n",
    "        if self.normalize:\n",
    "            X = self.scaler.transform(X)\n",
    "\n",
    "        pred = X.dot(self.coefficients) + self.intercept\n",
    "        \n",
    "        root_mean_squared_error = np.sqrt(np.mean((pred - y) ** 2))\n",
    "\n",
    "        return root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanmcaleavy/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e+02, tolerance: 5.436e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomLasso' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m Ridge_object \u001b[38;5;241m=\u001b[39m CustomLasso(alpha\u001b[38;5;241m=\u001b[39malpha, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m Ridge_object\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 40\u001b[0m coef \u001b[38;5;241m=\u001b[39m \u001b[43mRidge_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\n\u001b[1;32m     42\u001b[0m nonZero \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(coef \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(coef)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomLasso' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assume X_train, X_test, y_train, y_test are already defined as pandas DataFrames/Series\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = X_train.fillna(0.5)\n",
    "X_test = X_test.fillna(0.5)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "alphas = [1e-7, 1e-5, 1e-3, 5e-3, 0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "non_zeros = []\n",
    "norms = []\n",
    "RMSE = []\n",
    "\n",
    "non_zeros_normalized = []\n",
    "norms_normalized = []\n",
    "RMSE_normalized = []\n",
    "\n",
    "# Track zeroed-out features\n",
    "zeroed_features = []\n",
    "\n",
    "best_alpha_norm = 0\n",
    "best_alpha_nonNorm = 0\n",
    "unormalized_min_rmse = np.inf\n",
    "normalized_min_rmse = np.inf\n",
    "\n",
    "# Store feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Lasso without normalization\n",
    "    Ridge_object = CustomLasso(alpha=alpha, normalize=False)\n",
    "    Ridge_object.fit(X_train, y_train)\n",
    "    coef = Ridge_object.coefficients  # Fixed here\n",
    "    \n",
    "    nonZero = np.sum(coef != 0)\n",
    "    norm = np.linalg.norm(coef)\n",
    "    rmse = Ridge_object.evaluate(X_test, y_test)  # Use the evaluate method to compute RMSE\n",
    "\n",
    "    non_zeros.append(nonZero)\n",
    "    norms.append(norm)\n",
    "    RMSE.append(rmse)\n",
    "\n",
    "    # Track zeroed-out features\n",
    "    zeroed_out = feature_names[coef == 0]\n",
    "    zeroed_features.append((alpha, zeroed_out.tolist()))\n",
    "\n",
    "    if rmse < unormalized_min_rmse:\n",
    "        unormalized_min_rmse = rmse\n",
    "        best_alpha_nonNorm = alpha\n",
    "\n",
    "    # Lasso with normalization\n",
    "    Ridge_object_normalized = CustomLasso(alpha=alpha, normalize=True)\n",
    "    Ridge_object_normalized.fit(X_train, y_train)\n",
    "    coef_normalized = Ridge_object_normalized.coefficients  # Fixed here\n",
    "    \n",
    "    nonZeroNormalized = np.sum(coef_normalized != 0)\n",
    "    normNormalized = np.linalg.norm(coef_normalized)\n",
    "    rmseNormalized = Ridge_object_normalized.evaluate(X_test, y_test)  # Use the evaluate method\n",
    "\n",
    "    non_zeros_normalized.append(nonZeroNormalized)\n",
    "    norms_normalized.append(normNormalized)\n",
    "    RMSE_normalized.append(rmseNormalized)\n",
    "\n",
    "    if rmseNormalized < normalized_min_rmse:\n",
    "        normalized_min_rmse = rmseNormalized\n",
    "        best_alpha_Norm = alpha\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "log_alphas = np.log10(alphas)\n",
    "\n",
    "ax1.plot(log_alphas, non_zeros_normalized, label=\"Normalized\")\n",
    "ax1.plot(log_alphas, non_zeros, label=\"Non-Normalized\")\n",
    "ax1.set_title('Non-zero Coefficients')\n",
    "ax1.set_xlabel('log_10(alpha)')\n",
    "ax1.set_ylabel('Non-zero Coefficients')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(log_alphas, norms_normalized, label=\"Normalized\")\n",
    "ax2.plot(log_alphas, norms, label=\"Non-Normalized\")\n",
    "ax2.set_title('Norm of Coefficients')\n",
    "ax2.set_xlabel('log_10(alpha)')\n",
    "ax2.set_ylabel('Norm of w')\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(log_alphas, RMSE_normalized, label=\"Normalized\")\n",
    "ax3.plot(log_alphas, RMSE, label=\"Non-Normalized\")\n",
    "ax3.set_title('RMSE')\n",
    "ax3.set_xlabel('log_10(alpha)')\n",
    "ax3.set_ylabel('RMSE')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the best alpha values and errors\n",
    "print(f\"Minimum error non_normalized for alpha {best_alpha_nonNorm}: {unormalized_min_rmse}\")\n",
    "print(f\"Minimum error normalized for alpha {best_alpha_Norm}: {normalized_min_rmse}\")\n",
    "\n",
    "# Display zeroed-out features\n",
    "print(\"\\nZeroed-out features by alpha:\")\n",
    "for alpha, features in zeroed_features:\n",
    "    print(f\"Alpha {alpha}: Zeroed-out features = {features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(filepath, target_column):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "train_filepath = \"/Users/ethanmcaleavy/Documents/CompSci /CSCI 4622/Project/CSCI4622_project_lashley_lads/data_for_KNN_train.csv\"\n",
    "test_filepath = \"/Users/ethanmcaleavy/Documents/CompSci /CSCI 4622/Project/CSCI4622_project_lashley_lads/data_for_KNN_test.csv\"    \n",
    "target_column = \"log_price\" \n",
    "\n",
    "X_train, y_train = load_data(train_filepath, target_column)\n",
    "X_test, y_test = load_data(test_filepath, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4568665166161784\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = X_train.fillna(0.5)\n",
    "X_test = X_test.fillna(0.5)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "lasso = Lasso(alpha=0.1) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda Base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
